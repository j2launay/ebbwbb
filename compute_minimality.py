import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import spacy
from similarity_functions import l0_similarity_text, cosine_similarity_text, pairwise_similarity_text
from generate_dataset import generate_dataset, preparing_dataset
from counterfactuals_methods import Counterfactuals
from text_function_experiments import TextExplainer, remove_stopwords
import numpy as np
import time
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

def compare_similarity_with_opaque_explanation(dataset_name, transparent_method_name, opaque_method_name, black_boxes):
    """
    Function to generate a counterfactual with the input transparent method to compare with the counterfactuals already 
    generated by the opaque methods. This function allows to store the similarity based on 4 different metrics and the 
    runtime of each method to generate a counterfactual.
    Args:   dataset_name: string of the dataset name
            transparent_method_name: string of the counterfactual method use to generate a new counterfactual
            opaque_method_name: string of the opaque counterfactual method use as an opponent
            black_boxes: array of sklearn classifier
    Return: 
    """
    def get_similarity_text(text1, text2):
        doc1=nlp(text1)
        doc2=nlp(text2)
        return doc1.similarity(doc2)

    dataframe = pd.DataFrame(columns=['dataset', 'bb', 'wb similarity', 'bb similarity', 'metric', 'opaque method', 'transparent method', 'wb time', 'bb time'])
    for black_box in black_boxes:
        black_box_name = "DNN" if "MLP" in type(black_box).__name__ else "RF"

        if opaque_method_name == "xspells":
            black_box_explanation_results = pd.read_csv("./results/xspells/output/" + dataset_name + "_" + black_box_name + "3.csv")
            targets = black_box_explanation_results['original text']
            cfs = black_box_explanation_results['counter exemplars']
            times = black_box_explanation_results['time to generate']
        else:
            black_box_cfgan = "dnn" if "MLP" in type(black_box).__name__ else "rf"  
            black_box_explanation_results = pd.read_json("./results/counterfactual_gan/results/" + dataset_name + "_" + black_box_cfgan + "_0.json")
            targets = black_box_explanation_results['original_data'][0][:100]
            cfs = black_box_explanation_results['counterfactuals'][0][:100]
            times = black_box_explanation_results['inference_time_per_text_2'][0][:100]
        print(black_box_explanation_results)
        
        x, y, class_names = generate_dataset(dataset_name)
        x_train, _, y_train, _, x_train_vectorize, _, vectorizer = preparing_dataset(x, y, dataset_name)

        black_box = black_box.fit(x_train, y_train)
        def model_predict(text):
            if type(text) is str or type(text) is list:
                text = vectorizer.transform(text)
            return black_box.predict(text)
        def model_predict_proba(text):
            return black_box.predict_proba(vectorizer.transform(text))
        
        if "sedc" in transparent_method_name or "random" in transparent_method_name:
            explainer = TextExplainer(class_names, model_predict, model_predict_proba, vectorizer, \
                verbose=False, extend_nlp=x_train_vectorize, corpus=x_train_vectorize)

        opaque_explanation_similarity_l0, opaque_explanation_similarity_cosine, opaque_explanation_similarity_pairwise, opaque_explanation_similarity_spacy = [], [], [], []
        transparent_explan_similarity_l0, transparent_explan_similarity_cosine, transparent_explan_similarity_pairwise, transparent_explan_similarity_spacy = [], [], [], []
        for target, cf, bb_time in zip(targets, cfs, times):
            instance_array = [target]
            instance_vectorized = vectorizer.transform(instance_array)
            if opaque_method_name == "xspells":
                try:
                    cf = cf.split("',")
                    cf = cf[0][2:]
                except AttributeError:
                    print("attribute error", cf)
                
            if "sedc" in transparent_method_name or "random" in transparent_method_name:
                counterfactuals = Counterfactuals(instance_vectorized, target, model_predict, method=transparent_method_name, nlp=explainer.nlp, corpus=explainer.corpus)
            else:
                counterfactuals = Counterfactuals(instance_vectorized, target, model_predict, method=transparent_method_name, nlp=nlp)
            print()
            print("initialized")
            try:
                test += 2
            except NameError:
                start_time = time.time()
                closest_counterfactual, _, _, _ = counterfactuals.find_counterfactual()
                wb_time = time.time() - start_time
                print("cf by " + transparent_method_name, closest_counterfactual)
                print("target", target)
                print("cf by " + opaque_method_name, cf)
                target = remove_stopwords(target, nlp)
                cf = remove_stopwords(cf, nlp)
                closest_counterfactual = remove_stopwords(closest_counterfactual, nlp)
                
                # Compute the l0 similarity of the counterfactuals to the input text
                bb_l0 = l0_similarity_text(target, cf)
                opaque_explanation_similarity_l0.append(bb_l0)
                wb_l0 = l0_similarity_text(target, closest_counterfactual)
                transparent_explan_similarity_l0.append(wb_l0)

                # Compute the pairwise similarity of the counterfactuals to the input text
                bb_pairwise = pairwise_similarity_text(target, cf)
                opaque_explanation_similarity_pairwise.append(bb_pairwise)
                wb_pairwise = pairwise_similarity_text(target, closest_counterfactual)
                transparent_explan_similarity_pairwise.append(wb_pairwise)

                # Compute the cosine similarity of the counterfactuals to the input text
                bb_cosine = cosine_similarity_text(target, cf)
                opaque_explanation_similarity_cosine.append(bb_cosine)
                wb_cosine = cosine_similarity_text(target, closest_counterfactual)
                transparent_explan_similarity_cosine.append(wb_cosine)

                # Compute the spacy similarity of the counterfactuals to the input text
                bb_spacy = get_similarity_text(target, cf)
                opaque_explanation_similarity_spacy.append(bb_spacy)
                wb_spacy = get_similarity_text(target, closest_counterfactual)
                transparent_explan_similarity_spacy.append(wb_spacy)
                similarity_array = pd.DataFrame({'wb similarity':[wb_l0, wb_pairwise, wb_cosine, wb_spacy], 'bb similarity': \
                    [bb_l0, bb_pairwise, bb_cosine, bb_spacy], 'metric': ["l0", "pairwise", "cosine", "spacy"], "dataset": dataset_name, \
                        "bb": black_box_name, 'bb time':bb_time, 'wb time': wb_time, 'opaque method': opaque_method_name, 'transparent method':transparent_method_name,})
                dataframe = pd.concat([dataframe, similarity_array])
                dataframe.to_csv("./results/similarity/" + dataset_name + "_" + opaque_method_name + "_" + transparent_method_name + "_similarity.csv")     
            except:
                pass
        
        print()
        print("moyenne de " + opaque_method_name + ":" , np.mean(opaque_explanation_similarity_spacy, dtype=np.float64))
        print("moyenne de " + transparent_method_name + ":" ,np.mean(transparent_explan_similarity_spacy, dtype=np.float64))
    
if __name__ == "__main__":
    nlp = spacy.load("./model/en_core_web_lg")#if doesn't exist, init TextExplainer() obect in text_function_experiments first
    datasets_name = ['polarity']#'polarity', 'spam', 'fake']
    black_boxes = [MLPClassifier(), RandomForestClassifier()]
    methods = ['random']#['sedc', 'growing_net', 'growing_language', 'random']
    black_boxes_explanation = ['xspells']#['xspells', 'cf_gan']
    for dataset_name in datasets_name:
        for black_box_explanation in black_boxes_explanation:
            for method in methods:
                compare_similarity_with_opaque_explanation(dataset_name, method, black_box_explanation, black_boxes)
